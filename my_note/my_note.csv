subject|description
operting system used|windows 10 64 bit
Activate.ps1 cannot be loaded because running scripts is disabled on this system|https://stackoverflow.com/questions/4037939/powershell-says-execution-of-scripts-is-disabled-on-this-system
command to create a virtual environment "venv"|python -m venv venv
command to activate environment "env"|"venv\Scripts\activate" => it runs the file "C:\Users\nhhp\Documents\GitHub\end-to-end-data-engineering-project-4413618\venv\Scripts\activate.bat"
command to de-activate environment "env"|"venv\Scripts\deactivate " => it runs the file "C:\Users\nhhp\Documents\GitHub\end-to-end-data-engineering-project-4413618\venv\Scripts\deactivate.bat"
command to install all dependencies|pip install -e ".[dev]"
command to set environment variables|"venv.bat" => it runs the file 
error filename too long| https://stackoverflow.com/questions/22575662/filename-too-long-in-git-for-windows
command to run airbyte after cloning https://github.com/airbytehq/airbyte.git and accessing folder airbyte|run-ab-platform.sh
error "postgres:5432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections" when creating source Postgres on Airbyte|ensure the docker container "big-star-container" has already been run, and the username & password between the config on Airbyte abd the config on tab Inspect of the container are similar
term "export" is not recognized as the name of a cmdlet, function, script file, or operable program|https://stackoverflow.com/questions/26368306/export-is-not-recognized-as-an-internal-or-external-command
https://www.linkedin.com/learning/end-to-end-data-engineering-project/initiating-your-dbt-project?resume=false|after active virtual environment venv, use command "call venv.bat"(https://www.youtube.com/watch?v=nYr9qwW48uw) to run the bat file to run to setup environment variables instead of manually running 1 by 1 each time you active the environment. Another approach is that you can update the above activate.bat (Note that this activate.bat is being ignored from pushing into git repository) so that you do not need to run the above command "call venv.bat" seperatedly. Another approach is that you can use "setx" to instead of "set" for the command "set" of venv.bat to setup environment variables at systematic Windows 10 level which applying into all environments (Note that it will overwrite the existing ones) (https://stackoverflow.com/questions/13222724/command-line-to-remove-an-environment-variable-from-the-os-level-configuration)
https://www.linkedin.com/learning/end-to-end-data-engineering-project/solution-add-a-freshness-check?resume=false|refer to dbt_source_freshness_20240821.PNG. You get error as highligted number 1 area if any wrong word, for example "databases" instead correct "database". You get errors as highligted number 2 area if following the video to use "_airbyte_normalized_at" instead because it does not exist in equivalent tables in my google cloud according to google_cloud.bigquery.*.PNG files
https://www.linkedin.com/learning/end-to-end-data-engineering-project/securing-your-data-with-dbt-tests?autoSkip=true&resume=false|refer to dbt_test_20240822_08*.PNG files. In dbt_test_20240822_0800.PNG, you get highlighted-number-1 warning if following the video to use "tests" instead. You also get highlighted-number-1 errors if using wrong value lie "not null" insteaddd. You also get message "Nothing to do" if using "data-tests" instead. Refer to dbt_test_20240822_0801.PNG for the expected result.
https://www.linkedin.com/learning/end-to-end-data-engineering-project/securing-your-data-with-dbt-tests?resume=false|refer to dbt_test_20240822_2151.PNG. You get error as highligted number 1 area if any wrong indentation. For example, the number of spaces before the word "accepted_values:" =  the number of spaces before the word "accepted_values:"
command to initialize a new Dagster project and create directories and files that load assets from an existing dbt project|"dagster-dbt project scaffold --project-name my_dagster_orchestration --dbt-project-dir %DBT_PROJECT_DIR%" or "dagster-dbt project scaffold --project-name my_dagster_orchestration --dbt-project-dir C:\Users\nhhp\Documents\GitHub\end-to-end-data-engineering-project-4413618\dbt_transformation" according to https://docs.dagster.io/_apidocs/libraries/dagster-dbt. Note that we need to clone C:\Users\nhhp\Documents\GitHub\end-to-end-data-engineering-project-4413618\dbt_transformation\config\profiles.yml into C:\Users\nhhp\Documents\GitHub\end-to-end-data-engineering-project-4413618\dbt_transformation\profiles.yml in advance due to https://docs.dagster.io/integrations/dbt/using-dbt-with-dagster-plus
https://www.linkedin.com/learning/end-to-end-data-engineering-project/integrating-dbt-models-with-dagster-assets?resume=false|dagster_dev_20240831.PNG
https://www.linkedin.com/learning/end-to-end-data-engineering-project/integrating-airbyte-connections-with-dagster-assets?autoSkip=true&resume=false|dagster_dev_20240901_2250.PNG
https://www.linkedin.com/learning/end-to-end-data-engineering-project/materializing-assets-using-dagit?resume=false|dagster_dev_20240901_2257.PNG and dagster_dev_20240901_2304.PNG
https://www.linkedin.com/learning/end-to-end-data-engineering-project/solution-add-a-schedule-to-your-data-pipeline?resume=false|dagster_dev_20240902.PNG
my container| C:\Users\nhhp\OneDrive\Storage\LINKEDIN\hands-on-introduction-data-engineering-4395021
https://docs.dagster.io/guides/dagster/recommended-project-structure|consider in the real project
https://www.secoda.co/learn/how-to-set-up-dbt-cloud-to-profiles-yml|consider if applying the learning techiques of this course in the real life